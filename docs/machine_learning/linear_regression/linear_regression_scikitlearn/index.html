<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>Chris Albon  | Linear Regression</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="generator" content="Hugo 0.56.3" />
    
    
      <META NAME="ROBOTS" CONTENT="NOINDEX, NOFOLLOW">
    

    
    
      <link href="/dist/css/app.d98f2eb6bcd1eaedb7edf166bd16af26.css" rel="stylesheet">
    

    

    
      
    

    

    <meta property="og:title" content="Linear Regression" />
<meta property="og:description" content="A simple example of linear regression in scikit-learn" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/machine_learning/linear_regression/linear_regression_scikitlearn/" />
<meta property="article:published_time" content="2017-12-20T11:53:49-07:00" />
<meta property="article:modified_time" content="2017-12-20T11:53:49-07:00" />
<meta itemprop="name" content="Linear Regression">
<meta itemprop="description" content="A simple example of linear regression in scikit-learn">


<meta itemprop="datePublished" content="2017-12-20T11:53:49-07:00" />
<meta itemprop="dateModified" content="2017-12-20T11:53:49-07:00" />
<meta itemprop="wordCount" content="836">



<meta itemprop="keywords" content="" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Linear Regression"/>
<meta name="twitter:description" content="A simple example of linear regression in scikit-learn"/>

  </head>

  <body class="ma0 avenir bg-near-white">

    
   
  

  <header>
    <div class="bg-black">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="" class="f3 fw2 hover-white no-underline white-90 dib">
      Chris Albon
    </a>
    <div class="flex-l items-center">
      

      
      











    </div>
  </div>
</nav>

    </div>
  </header>



    <main class="pb7" role="main">
      
  
  <article class="flex-l flex-wrap justify-between mw8 center ph3">

    <header class="mt4 w-100">
      <p class="f6 b helvetica tracked">
          
        MACHINE_LEARNINGS
      </p>
      <h1 class="f1 athelas mb1">Linear Regression</h1>
      
      <time class="f6 mv4 dib tracked" datetime="2017-12-20T11:53:49-07:00">December 20, 2017</time>
      
      
    </header>

    <section class="nested-copy-line-height lh-copy serif f4 nested-links nested-img mid-gray pr4-l w-two-thirds-l">

<p>Sources: <a href="http://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html#example-linear-model-plot-ols-py">scikit-learn</a>, <a href="http://robertgrantstats.co.uk/drawmydata.html">DrawMyData</a>.</p>

<p>The purpose of this tutorial is to give a brief introduction into the logic of statistical model building used in machine learning. If you want to read more about the theory behind this tutorial, check out <a href="https://www.amazon.com/Introduction-Statistical-Learning-Applications-Statistics/dp/1461471370">An Introduction To Statistical Learning</a>.</p>

<p>Let us get started.</p>

<h2 id="preliminary">Preliminary</h2>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">linear_model</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span></code></pre></div>
<h2 id="load-data">Load Data</h2>

<p>With those libraries added, let us load the dataset (the dataset is avaliable in his site&rsquo;s GitHub repo).</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># Load the data</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;../data/simulated_data/battledeaths_n300_cor99.csv&#39;</span><span class="p">)</span>

<span class="c1"># Shuffle the data&#39;s rows (This is only necessary because of the way I created</span>
<span class="c1"># the data using DrawMyData. This would not normally be necessary with a real analysis).</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">frac</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></code></pre></div>
<h2 id="explore-data">Explore Data</h2>

<p>Let us take a look at the first few rows of the data just to get an idea about it.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># View the first few rows</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span></code></pre></div>
<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>friendly_battledeaths</th>
      <th>enemy_battledeaths</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>7</th>
      <td>8.2051</td>
      <td>9.6154</td>
    </tr>
    <tr>
      <th>286</th>
      <td>88.7179</td>
      <td>86.1538</td>
    </tr>
    <tr>
      <th>164</th>
      <td>14.3590</td>
      <td>8.8462</td>
    </tr>
    <tr>
      <th>180</th>
      <td>38.9744</td>
      <td>36.5385</td>
    </tr>
    <tr>
      <th>89</th>
      <td>93.0769</td>
      <td>93.0769</td>
    </tr>
  </tbody>
</table>
</div>

<p>Now let us plot the data so we can see it&rsquo;s structure.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># Plot the two variables against eachother</span>
<span class="n">df</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;friendly_battledeaths&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;enemy_battledeaths&#39;</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s1">&#39;scatter&#39;</span><span class="p">)</span></code></pre></div>
<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x1145cdb00&gt;
</code></pre>

<p><img src="linear_regression_scikitlearn_12_1.png" alt="png" /></p>

<h2 id="break-data-up-into-training-and-test-datasets">Break Data Up Into Training And Test Datasets</h2>

<p>Now for the real work. To judge how how good our model is, we need something to test it against. We can accomplish this using a technique called cross-validation. Cross-validation can get much more complicated and powerful, but in this example we are going do the most simple version of this technique.</p>

<h3 id="steps">Steps</h3>

<ol>
<li>Divide the dataset into two datasets: A &lsquo;training&rsquo; dataset that we will use to train our model and a &lsquo;test&rsquo; dataset that we will use to judge the accuracy of that model.</li>
<li>Train the model on the &lsquo;training&rsquo; data.</li>
<li>Apply that model to the test data&rsquo;s X variable, creating the model&rsquo;s guesses for the test data&rsquo;s Ys.</li>

<li><p>Compare how close the model&rsquo;s predictions for the test data&rsquo;s Ys were to the actual test data Ys.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># Create our predictor/independent variable</span>
<span class="c1"># and our response/dependent variable</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;friendly_battledeaths&#39;</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;enemy_battledeaths&#39;</span><span class="p">]</span>

<span class="c1"># Create our test data from the first 30 observations</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">30</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">30</span><span class="p">]</span>

<span class="c1"># Create our training data from the remaining observations</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="mi">30</span><span class="p">:]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="mi">30</span><span class="p">:]</span></code></pre></div></li>
</ol>

<h2 id="train-the-linear-model">Train The Linear Model</h2>

<p>Let us train the model using our training data.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># Create an object that is an ols regression</span>
<span class="n">ols</span> <span class="o">=</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">LinearRegression</span><span class="p">()</span></code></pre></div><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># Train the model using our training data</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ols</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span></code></pre></div>
<h2 id="view-the-results">View The Results</h2>

<p>Here are some basic outputs of the model, notably the coefficient and the R-squared score.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># View the training model&#39;s coefficient</span>
<span class="n">model</span><span class="o">.</span><span class="n">coef_</span></code></pre></div>
<pre><code>array([ 0.97696721])
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># View the R-Squared score</span>
<span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span></code></pre></div>
<pre><code>0.98573393818904709
</code></pre>

<p>Now that we have used the training data to train a model, called <code>model</code>, we can apply it to the test data&rsquo;s Xs to make predictions of the test data&rsquo;s Ys.</p>

<p>Previously we used <code>X_train</code> and <code>y_train</code> to train a linear regression model, which we stored as a variable called <code>model</code>. The code <code>model.predict(X_test)</code> applies the trained model to the <code>X_test</code> data, data the model has never seen before to make predicted values of Y.</p>

<p>This can easily be seen by simply running the code:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># Run the model on X_test and show the first five results</span>
<span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">])</span></code></pre></div>
<pre><code>[7.4633347104887342,
 86.121700007313791,
 13.475493202059415,
 37.523931774900845,
 90.380300060086256]
</code></pre>

<p>This array of values is the model&rsquo;s best guesses for the values of the test data&rsquo;s Ys. Compare them to the actual test data Y values:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># View the first five test Y values</span>
<span class="nb">list</span><span class="p">(</span><span class="n">y_test</span><span class="p">)[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span></code></pre></div>
<pre><code>[9.6153999999999993,
 86.153800000000004,
 8.8461999999999996,
 36.538499999999999,
 93.076899999999995]
</code></pre>

<p>The difference between the model&rsquo;s predicted values and the actual values is how is we judge as model&rsquo;s accuracy, because a perfectly accurate model would have residuals of zero.</p>

<p>However, to judge a model, we want a single statistic (number) that we can use as a measure. We want this measure to capture the difference between the predicted values and the actual values across all observations in the data.</p>

<p>The most common statistic used for quantitative Ys is the <strong>residual sum of squares</strong>:</p>

<p>$$ RSS = \sum_{i=1}^{n}(y_{i}-f(x_{i}))^{2} $$</p>

<p>Don&rsquo;t let the mathematical notation throw you off:</p>

<ul>
<li>$f(x_{i})$ is the model we trained: <code>model.predict(X_test)</code></li>
<li>$y_{i}$ is the test data&rsquo;s y: <code>y_test</code></li>
<li>$^{2}$ is the exponent: <code>**2</code></li>
<li>$\sum_{i=1}^{n}$ is the summation: <code>.sum()</code></li>
</ul>

<p>In the residual sum of squares, for each observation we find the difference between the model&rsquo;s predicted Y and the actual Y, then square that difference to make all the values positive. Then we add all those squared differences together to get a single number. The final result is a statistic representing how far the model&rsquo;s predictions were from the real values.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># Apply the model we created using the training data </span>
<span class="c1"># to the test data, and calculate the RSS.</span>
<span class="p">((</span><span class="n">y_test</span> <span class="o">-</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">))</span> <span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span></code></pre></div>
<pre><code>313.6087355571951
</code></pre>

<p>Note: You can also use Mean Squared Error, which is RSS divided by the degrees of freedom. But I find it helpful to think in terms of RSS.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># Calculate the MSE</span>
<span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span> <span class="o">-</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">**</span><span class="mi">2</span><span class="p">)</span></code></pre></div>
<pre><code>10.45362451857317
</code></pre>
<ul class="pa0">
  
</ul>
<div class="mt6">
      
      
      </div>
    </section>

    <aside class="w-30-l mt6-l">




</aside>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="" >
    &copy; 2019 Chris Albon
  </a>
    <div>










</div>
  </div>
</footer>

    

  <script src="/dist/js/app.3fc0f988d21662902933.js"></script>


  </body>
</html>
