<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>Chris Albon  | Cross Validation Pipeline</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="generator" content="Hugo 0.56.3" />
    
    
      <META NAME="ROBOTS" CONTENT="NOINDEX, NOFOLLOW">
    

    
    
      <link href="/dist/css/app.d98f2eb6bcd1eaedb7edf166bd16af26.css" rel="stylesheet">
    

    

    
      
    

    

    <meta property="og:title" content="Cross Validation Pipeline" />
<meta property="og:description" content="Cross validaton pipeline with scikit." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/machine_learning/model_evaluation/cross_validation_pipeline/" />
<meta property="article:published_time" content="2017-12-20T11:53:49-07:00" />
<meta property="article:modified_time" content="2017-12-20T11:53:49-07:00" />
<meta itemprop="name" content="Cross Validation Pipeline">
<meta itemprop="description" content="Cross validaton pipeline with scikit.">


<meta itemprop="datePublished" content="2017-12-20T11:53:49-07:00" />
<meta itemprop="dateModified" content="2017-12-20T11:53:49-07:00" />
<meta itemprop="wordCount" content="461">



<meta itemprop="keywords" content="" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Cross Validation Pipeline"/>
<meta name="twitter:description" content="Cross validaton pipeline with scikit."/>

  </head>

  <body class="ma0 avenir bg-near-white">

    
   
  

  <header>
    <div class="bg-black">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="" class="f3 fw2 hover-white no-underline white-90 dib">
      Chris Albon
    </a>
    <div class="flex-l items-center">
      

      
      











    </div>
  </div>
</nav>

    </div>
  </header>



    <main class="pb7" role="main">
      
  
  <article class="flex-l flex-wrap justify-between mw8 center ph3">

    <header class="mt4 w-100">
      <p class="f6 b helvetica tracked">
          
        MACHINE_LEARNINGS
      </p>
      <h1 class="f1 athelas mb1">Cross Validation Pipeline</h1>
      
      <time class="f6 mv4 dib tracked" datetime="2017-12-20T11:53:49-07:00">December 20, 2017</time>
      
      
    </header>

    <section class="nested-copy-line-height lh-copy serif f4 nested-links nested-img mid-gray pr4-l w-two-thirds-l">

<p>The code below does a lot in only a few lines. To help explain things, here are the steps that code is doing:</p>

<ol>
<li>Split the raw data into three folds. Select one for testing and two for training.</li>
<li>Preprocess the data by scaling the training features.</li>
<li>Train a support vector classifier on the training data.</li>
<li>Apply the classifier to the test data.</li>
<li>Record the accuracy score.</li>
<li>Repeat steps 1-5 two more times, once for each fold.</li>
<li>Calculate the mean score for all the folds.</li>
</ol>

<h2 id="preliminaries">Preliminaries</h2>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">preprocessing</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">cross_validation</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">svm</span></code></pre></div>
<h2 id="load-data">Load Data</h2>

<p>For this tutorial we will use the famous <a href="https://en.wikipedia.org/wiki/Iris_flower_data_set">iris dataset</a>. The iris data contains four measurements of 150 iris flowers and their species. We will use a support vector classifier to predict the species of the iris flowers.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># Load the iris test data</span>
<span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span></code></pre></div><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># View the iris data features for the first three rows</span>
<span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">]</span></code></pre></div>
<pre><code>array([[ 5.1,  3.5,  1.4,  0.2],
       [ 4.9,  3. ,  1.4,  0.2],
       [ 4.7,  3.2,  1.3,  0.2]])
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># View the iris data target for first three rows. &#39;0&#39; means it flower is of the setosa species.</span>
<span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">]</span></code></pre></div>
<pre><code>array([0, 0, 0])
</code></pre>

<h2 id="create-classifier-pipeline">Create Classifier Pipeline</h2>

<p>Now we create a pipeline for the data. First, the pipeline preprocesses the data by scaling the feature variable&rsquo;s values to mean zero and unit variance. Second, the pipeline trains a support classifier on the data with <code>C=1</code>. <code>C</code> is the cost function for the margins. The higher the C, the less tolerant the model is for observations being on the wrong side of the hyperplane.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># Create a pipeline that scales the data then trains a support vector classifier</span>
<span class="n">classifier_pipeline</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span></code></pre></div>
<h2 id="cross-validation">Cross Validation</h2>

<p>Scikit provides a great helper function to make it easy to do cross validation. Specifically, the code below splits the data into three folds, then executes the classifier pipeline on the iris data.</p>

<p>Important note from the <a href="http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.cross_val_score.html#sklearn.cross_validation.cross_val_score">scikit docs</a>: <em>For integer/None inputs, if y is binary or multiclass, StratifiedKFold used. If the estimator is a classifier or if y is neither binary nor multiclass, KFold is used.</em></p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># KFold/StratifiedKFold cross validation with 3 folds (the default)</span>
<span class="c1"># applying the classifier pipeline to the feature and target data</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_validation</span><span class="o">.</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">classifier_pipeline</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span></code></pre></div>
<h2 id="evaluate-model">Evaluate Model</h2>

<p>Here is the output of our 3 KFold cross validation. Each value is the accuracy score of the support vector classifier when leaving out a different fold. There are three values because there are three folds. A higher accuracy score, the better.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">scores</span></code></pre></div>
<pre><code>array([ 0.98039216,  0.90196078,  0.97916667])
</code></pre>

<p>To get an good measure of the model&rsquo;s accuracy, we calculate the mean of the three scores. This is our measure of model accuracy.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span></code></pre></div>
<pre><code>0.95383986928104569
</code></pre>
<ul class="pa0">
  
</ul>
<div class="mt6">
      
      
      </div>
    </section>

    <aside class="w-30-l mt6-l">




</aside>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="" >
    &copy; 2019 Chris Albon
  </a>
    <div>










</div>
  </div>
</footer>

    

  <script src="/dist/js/app.3fc0f988d21662902933.js"></script>


  </body>
</html>
